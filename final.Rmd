---
title: "Math 390 Final Project"
author: "Moshe Weiss"
date: "5/10/2019"
output: html_document
---



```{r}
#Dependencies
pacman::p_load(dplyr, tidyr, magrittr, mlr, missForest)
pacman::p_install_gh("kapelner/YARF", subdir = "YARF", ref = "dev")
pacman::p_install_gh("kapelner/YARF", subdir = "YARFJARs", ref = "dev")
pacman::p_install_gh("kapelner/YARF", subdir = "YARF", ref = "dev")
pacman::p_load(YARF)
```

```{r}
#Data Cleaning and Imputation
housing_data = read.csv("writing_assignments/housing_data_2016_2017.csv", stringsAsFactors = FALSE)
#fix feature selection
q_housing = as.data.frame(housing_data)

q_housing %<>%
  select(num_bedrooms, num_floors_in_building, kitchen_type, maintenance_cost, num_full_bathrooms, num_total_rooms, sq_footage, walk_score, dining_room_type, fuel_type, cats_allowed, dogs_allowed, coop_condo, approx_year_built, garage_exists, sale_price) %>%
  
  mutate(kitchen_type = tolower(kitchen_type)) %>%
  mutate(kitchen_type = ifelse(substr(.$kitchen_type,1,3) == "eff","eff", ifelse(substr(.$kitchen_type,1,3) == "eat","eatin",ifelse(substr(.$kitchen_type,1,3) == "com","combo",ifelse(substr(.$kitchen_type,1,3) == "non","none",NA))))) %>%
  mutate(kitchen_type = factor(kitchen_type, ordered = FALSE)) %>%
  mutate(dining_room_type = factor(tolower(dining_room_type), ordered = FALSE)) %>%
  mutate(fuel_type = factor(tolower(fuel_type), ordered = FALSE)) %>%
  mutate(maintenance_cost = as.numeric(factor(maintenance_cost, ordered = FALSE))) %>%
  mutate(dogs_allowed = ifelse(substr(.$dogs_allowed, 1, 1) == "y", 1, 0)) %>%
  mutate(cats_allowed = ifelse(substr(.$cats_allowed, 1, 1) == "y", 1, 0)) %>%
  mutate(sale_price =  as.numeric(gsub('[$,]', '', q_housing$sale_price))) %>%
  mutate(coop_condo = factor(tolower(coop_condo))) %>%
  mutate(garage_exists = ifelse(is.na(garage_exists), 0, 1)) #%>%
#ID col for selecting missing y's
  #mutate(id = 1:nrow(q_housing))

#place 2 none values in other
  q_housing$dining_room_type[q_housing$dining_room_type == "none" & !is.na(q_housing$dining_room_type)] = "other"

#place 2 dining area values in other
  q_housing$dining_room_type[q_housing$dining_room_type == "dining area" & !is.na(q_housing$dining_room_type)] = "other"

#place 3 none values for fuel_type in other  
  q_housing$fuel_type[q_housing$fuel_type == "none" & !is.na(q_housing$fuel_type)] = "other"
  


#identifying missing y's

# naEntries = q_housing %>%
#               filter(is.na(sale_price))
# modellingEntries = setdiff(q_housing, naEntries)

missingTable = tbl_df(apply(is.na(q_housing), 2, as.numeric))

colnames(missingTable) = paste("is_missing_", colnames(q_housing), sep = "")
missingTable = tbl_df(t(unique(t(missingTable))))
missingTable %<>% 
  select_if(function(x){sum(x) > 0})

imp_q_housing = missForest(q_housing, sampsize = rep(525, ncol(q_housing)))$ximp

#Includes missingness in dataset. No significant difference observed.
  #imp_q_housing = cbind(imp_q_housing, missingTable)


#Remove all rows with imputed sale_price
  #This lowers our R squared by a lot, but is probably more representative of our
  #predictive power.

#imp_q_housing = imp_q_housing[modellingEntries$id,]

#imp_q_housing$id = NULL
```

```{r}
#REGRESSION OLS
modeling_task = makeRegrTask(data = imp_q_housing, target = "sale_price") 
algorithm = makeLearner("regr.lm")
validation = makeResampleDesc("CV", iters = 5) #instantiate the 5-fold CV
pred = resample(algorithm, modeling_task, validation, measures = list(rmse))
mean(pred$measures.test$rmse)
sd(pred$measures.test$rmse)

linmod = lm(sale_price ~ ., imp_q_housing)
summary(linmod)
```

```{r}
#REGRESSION TREE
options(java.parameters = "-Xmx4000m")
pacman::p_load(YARF)

test_prop = 0.1

train_indices = sample(1 : nrow(imp_q_housing), round((1 - test_prop) * nrow(imp_q_housing)))
imp_q_train = imp_q_housing[train_indices, ]
y_train = imp_q_train$sale_price
X_train = imp_q_train
X_train$sale_price = NULL

test_indices = setdiff(1 : nrow(imp_q_train), train_indices)
imp_q_test = imp_q_housing[test_indices, ]
y_test = imp_q_test$sale_price
X_test = imp_q_test
X_test$sale_price = NULL

tree_mod = YARFCART(data.frame(X = X_train), y_train)
tree_mod
get_tree_num_nodes_leaves_max_depths(tree_mod)
illustrate_trees(tree_mod, max_depth = 4, open_file = TRUE, length_in_px_per_half_split = 30)
```

```{r}
#RANDOM FOREST

y = imp_q_housing$sale_price
X = imp_q_housing
X$sale_price= NULL

mod_rf = YARF(X, y, num_trees = 300)
mod_rf

illustrate_trees(mod_rf, max_depth = 4, open_file = TRUE, length_in_px_per_half_split = 30)

#mlr random forest
# modeling_task = makeRegrTask(data = imp_q_housing, target = "sale_price") 
# algorithm = makeLearner("regr.randomForest")
# validation = makeResampleDesc("CV", iters = 5) #instantiate the 5-fold CV
# pred = resample(algorithm, modeling_task, validation, measures = list(rmse))
# mean(pred$measures.test$rmse)
# sd(pred$measures.test$rmse)

test_prop = 0.1

train_indices = sample(1 : nrow(imp_q_housing), round((1 - test_prop) * nrow(imp_q_housing)))
imp_q_train = imp_q_housing[train_indices, ]
y_train = imp_q_train$sale_price
X_train = imp_q_train
X_train$sale_price = NULL

test_indices = setdiff(1 : nrow(imp_q_train), train_indices)
imp_q_test = imp_q_housing[test_indices, ]
y_test = imp_q_test$sale_price
X_test = imp_q_test
X_test$sale_price = NULL

holdout_mod_rf = YARF(X_train, y_train, num_trees = 300)
holdout_mod_rf

y_hat_test = predict(holdout_mod_rf, X_test)
holdout_rmse = sqrt(mean((y_test - y_hat_test)^2))
holdout_rmse
holdout_rsq = 1 - sum((y_test - y_hat_test)^2)/sum((y_test - mean(y))^2)
holdout_rsq

ggplot(aes(y_hat_test, y_test), data = data.frame(y_test, y_hat_test)) +
  geom_point(col = "darkgreen")+
  geom_abline(col = "black")
```

